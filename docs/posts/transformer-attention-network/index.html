<!DOCTYPE html>
<html lang="en">
<html class="dark light">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    

    
    
    
    <title>
         Embedding, attention, and transformers
        
    </title>

        
            <meta property="og:title" content="Embedding, attention, and transformers" />
        
     

     
         
     

     
         
    

    
    
        <link rel="icon" type="image/png" href=&#x2F;icon&#x2F;favicon.ico />
    

    
    
        <link href=https://ypark.github.io/fonts.css rel="stylesheet" />
    

    
    

    
    
        <script src=https://ypark.github.io/js/codeblock.js></script>
    

    
    
        <script src=https://ypark.github.io/js/toc.js></script>
    
    
    
    

    

	<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>

        <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
        </script>
        
            <script>
            MathJax = {
              tex: {
                  inlineMath: [['$', '$'], ['\\(', '\\)'], ['$$', '$$']]
              }
            };
            </script>
        

	<!-- <\!-- KaTeX CSS -\-> -->
	<!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.2/katex.min.css"> -->
	
	<!-- <\!-- KaTeX JS -\-> -->
	<!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.2/katex.min.js"></script> -->
	
	<!-- <\!-- Optional: KaTeX Auto-render extension -\-> -->
	<!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.2/contrib/auto-render.min.js"></script> -->
	
	<!-- <script> -->
	<!--   document.addEventListener("DOMContentLoaded", function() { -->
	<!--       renderMathInElement(document.body, { -->
	<!-- 	  delimiters: [ -->
	<!-- 	      {left: "$$", right: "$$", display: true}, -->
	<!-- 	      {left: "$", right: "$", display: false} -->
	<!-- 	  ] -->
	<!--       }); -->
	<!--   }); -->
	<!-- </script> -->

    

    
    <link rel="alternate" type="application/atom+xml" title="" href="https://ypark.github.io/atom.xml">


    
    
        <link rel="stylesheet" type="text/css" href=https://ypark.github.io/theme/light.css />
        <link id="darkModeStyle" rel="stylesheet" type="text/css" href="https://ypark.github.io/theme/dark.css" />
    

    <!-- Set the correct theme in the script -->
    <script src=https://ypark.github.io/js/themetoggle.js></script>
    
        <script>setTheme(getSavedTheme());</script>
    

    <link rel="stylesheet" type="text/css" media="screen" href=https://ypark.github.io/main.css />

    
</head>


<body>
    <div class="content">
        <header>
    <div class="main">
        <a href=https:&#x2F;&#x2F;ypark.github.io></a>

        <div class="socials">
            
            <a rel="me" href="https:&#x2F;&#x2F;github.com&#x2F;causalpathlab&#x2F;" class="social">
                <img alt=github src=https://ypark.github.io/social_icons/github.svg>
            </a>
            
        </div>
    </div>

    <nav>
        
        <a href=https://ypark.github.io style="margin-left: 0.5em">home</a>
        
        <a href=https://ypark.github.io/about style="margin-left: 0.5em">&#x2F;about</a>
        
        <a href=https://ypark.github.io/posts style="margin-left: 0.5em">&#x2F;posts</a>
        
        <a href=https://ypark.github.io/team style="margin-left: 0.5em">&#x2F;team</a>
        
        <a href=https://ypark.github.io/alumni style="margin-left: 0.5em">&#x2F;alumni</a>
        

        
        |<a id="dark-mode-toggle" onclick="toggleTheme(); event.preventDefault();" href="#">
            <img src=https://ypark.github.io/feather/sun.svg id="sun-icon" style="filter: invert(1);" alt="Light" />
            <img src=https://ypark.github.io/feather/moon.svg id="moon-icon" alt="Dark" />
        </a>

        <!-- Inititialize the theme toggle icons -->
        <script>updateItemToggleTheme()</script>
        
    </nav>
</header>


        
        
    
<main>
    <article>
        <div class="title">
            
            
    <div class="page-header">
        Embedding, attention, and transformers<span class="primary-color" style="font-size: 1.6em">.</span>
    </div>


                <div class="meta">
                    
                        Posted on <time>2025-04-10</time>
                    

                    

                    

                    
                    
                            <span class="tags-label"> :: Tags:</span>
                            <span class="tags">
                                    <a href="https://ypark.github.io/tags/attention/" class="post-tag">attention</a>, 
                                
                                    <a href="https://ypark.github.io/tags/architecture/" class="post-tag">architecture</a>, 
                                
                                    <a href="https://ypark.github.io/tags/network/" class="post-tag">network</a>, 
                                
                                    <a href="https://ypark.github.io/tags/transformer/" class="post-tag">transformer</a>, 
                                
                                    <a href="https://ypark.github.io/tags/embedding/" class="post-tag">embedding</a>
                                
                            </span>
                    

                    
                    
                        
                        
                            
                        

                        
                    

                    

                </div>
        </div>

        

        
        
        
            <div class="toc-container">
                <h1 class="toc-title">Table of Contents</h1>
                <ul class="toc-list">
                    
                        <li>
                            <a href="https://ypark.github.io/posts/transformer-attention-network/#1-how-should-we-embed-locate-genes-words-and-why-do-we-need-embedding">1. How should we &quot;embed&quot; (locate) genes (words)? And why do we need embedding?</a>
                            
                                <ul>
                                    
                                        <li>
                                            <a href="https://ypark.github.io/posts/transformer-attention-network/#a-document-or-cell-as-a-bag-of-words">A document (or cell) as a bag of words</a>
                                        </li>

                                        
                                            <ul>
                                                
                                                    <li>
                                                        <a href="https://ypark.github.io/posts/transformer-attention-network/#what-have-we-missed-with-the-bag-of-words-assumption">What have we missed with the bag-of-words assumption?</a>
                                                    </li>
                                                
                                            </ul>
                                        
                                    
                                        <li>
                                            <a href="https://ypark.github.io/posts/transformer-attention-network/#gene-embedding-is-like-word-embedding-in-nlp">Gene embedding is like word embedding in NLP</a>
                                        </li>

                                        
                                    
                                </ul>
                            
                        </li>
                    
                        <li>
                            <a href="https://ypark.github.io/posts/transformer-attention-network/#2-what-attention-mechanisms-can-do-with-gene-embedding-vectors">2. What attention mechanisms can do with gene embedding vectors?</a>
                            
                                <ul>
                                    
                                        <li>
                                            <a href="https://ypark.github.io/posts/transformer-attention-network/#how-can-we-represent-a-sentence-of-words-in-a-meaningful-way">How can we represent a sentence of words in a meaningful way?</a>
                                        </li>

                                        
                                    
                                        <li>
                                            <a href="https://ypark.github.io/posts/transformer-attention-network/#an-attention-mechanism-simplifies-this-sentence-generating-process">An attention mechanism simplifies this sentence-generating process.</a>
                                        </li>

                                        
                                    
                                        <li>
                                            <a href="https://ypark.github.io/posts/transformer-attention-network/#hashing-dictionary-and-query-key-and-value">Hashing, dictionary, and (query, key, and value)</a>
                                        </li>

                                        
                                    
                                </ul>
                            
                        </li>
                    
                        <li>
                            <a href="https://ypark.github.io/posts/transformer-attention-network/#3-can-attention-based-models-be-foundational-for-single-cell-rna-seq-modelling">3. Can attention-based models be foundational for single-cell RNA-seq modelling?</a>
                            
                        </li>
                    
                </ul>
            </div>
        
        

        <section class="body">
            <p>We hear lots of excitement about a transformer network. However, I did not find an easy explanation (at least to me) on why and how it works.</p>
<h2 id="1-how-should-we-embed-locate-genes-words-and-why-do-we-need-embedding"><a class="zola-anchor" href="#1-how-should-we-embed-locate-genes-words-and-why-do-we-need-embedding" aria-label="Anchor link for: 1-how-should-we-embed-locate-genes-words-and-why-do-we-need-embedding">1. How should we "embed" (locate) genes (words)? And why do we need embedding?</a></h2>
<p>Embedding is like mapping a gene expression value in some latent space well spread between the values. In other words, from a point in the embedding space, we can recover each gene's name and its expression value (or ranking). It's important to understand what the embedding of a gene onto $d$-dimensional space does. Since my mindset has been stuck in a matrix factorization-like model for many years, I find this embedding step quite counter-intuitive. My other complaint is that "embedding" is not a good terminology at all. I think the whole step is more closely related to "stochastic" registration, dictionary, etc (just my complaint).</p>
<h3 id="a-document-or-cell-as-a-bag-of-words"><a class="zola-anchor" href="#a-document-or-cell-as-a-bag-of-words" aria-label="Anchor link for: a-document-or-cell-as-a-bag-of-words">A document (or cell) as a bag of words</a></h3>
<p>While not doing explicit embedding, in a typical fully connected neural network layer, we mark (or implicitly embed) a gene to a unique index (a variable or a visible unit). However, gene expression counts are not uniquely handled. In other words, the same gene can be "replicated" as if we keep on adding its contribution to the next hidden layer. The underlying concept seems very similar to <a href="https://papers.nips.cc/paper_files/paper/2009/hash/31839b036f63806cba3f47b93af8ccb5-Abstract.html">Replicated Softmax: an Undirected Topic Model</a>.</p>
<p>If we have a softmax model that maps for each word $d=1,\ldots,D$, we would have the energy function (to be minimized):</p>
<p>$$E = -\sum_{d=1}^{D} \sum_{g} \sum_{k} W_{gk}^{(d)} v_{g}^{(d)} h_{k}$$</p>
<p>where we denote $g$ for a gene $g$ and $k$ for a factor/topic $k$; $v_{g}^{(d)} = 1$ if and only if a gene $g$ is present in a document $d$; each word $d$'s model have weights $W_{gk}^{(d)}$ between a topic $k$ and gene $g$.</p>
<p>Assuming all the models share the same weights, namely $W_{gk}^{(d)}=W_{gk}, \forall d \in [D]$, and $x_{g}$ counts the frequency of a gene $g$ across all the words in this document, we can simplify:</p>
<p>$$E = -\sum_{g} \sum_{k} W_{gk} x_{g} h_{k}$$</p>
<p>This makes sense if we take each document as "a bag of words," where each gene is independently drawn within a document, conditioning on the topic proportion and latent topic membership of the word.</p>
<h4 id="what-have-we-missed-with-the-bag-of-words-assumption"><a class="zola-anchor" href="#what-have-we-missed-with-the-bag-of-words-assumption" aria-label="Anchor link for: what-have-we-missed-with-the-bag-of-words-assumption">What have we missed with the bag-of-words assumption?</a></h4>
<p>Since bag-of-words models have been so successful for many years and seem good enough for single-cell modelling, it is hard to justify why we would need a more sophisticated language model. So, this is not an exhaustive survey on what the bag-of-words missed:</p>
<ol>
<li>
<p><em>Monotone contribution</em>: We cannot map gene (word) counts in a non-linear fashion, meaning that a higher count of a gene $g$ will always have more weight on the same gene $g$ toward the next layer, i.e., $W_{gk}$ will increase for a particular $h_{k}$. In NLP, double or triple negation expressions are difficult to understand with a bag-of-words model. If a certain housekeeping gene (ribosomal or mitochondrial) is just highly expressed, its influence will dominate and mask out subtle yet significant context-dependent changes.</p>
</li>
<li>
<p><em>Lack of dependency within a layer</em>: We need many layers to represent word-to-word non-linear relationships. A single layer of the softmax model cannot represent ordering or any sort of positional information across words. Using a softmax function or similar can have some effect of "lateral inhibition"-like mechanisms so that a sparse set of keywords can be selected for each topic. However, it can also make known or unknown stopwords appear across multiple topics without apparent meaning. There is no direct influence across topics that having some high-frequency word in one topic prevents the other topic from picking up the same words, except for some statistical pressure.</p>
</li>
</ol>
<h3 id="gene-embedding-is-like-word-embedding-in-nlp"><a class="zola-anchor" href="#gene-embedding-is-like-word-embedding-in-nlp" aria-label="Anchor link for: gene-embedding-is-like-word-embedding-in-nlp">Gene embedding is like word embedding in NLP</a></h3>
<p>An embedding can bring more flexibility on interpreting the number of the same word (gene) occurred within a document (cell).
First of all, what is "word embedding?" In <code>PyTorch</code>'s documentation for <a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html"><code>Embedding</code></a> class, it says:</p>
<ul>
<li><code>Input: (*), IntTensor or LongTensor of arbitrary shape containing the indices to extract</code> and</li>
<li><code>Output: (*,H), where * is the input shape and H = embedding_dim</code></li>
</ul>
<p>For <a href="https://github.com/bowang-lab/scGPT/blob/0cd3c73779e93e999789d52b4412e6c23baaa02b/scgpt/model/model.py#L723"><code>scGPT</code></a>, this embedding class is directly applied to integer-valued expression tensor.</p>
<p>In a nutshell, each cell is like a fixed length (number of words/tokens) document (or sentence) with tokens (genes). Discretized/binned gene expression levels on each gene (word) uniquely mapped onto some $d$-dimensional latent space. For instance, $x_{g}=1$ and $x_{g}=10$ are independently located apart from each other in some embedding space. Upon training, we may be able to tell whether $x_{g}=1$ and $x_{g}=10$ mean semantically similar but very different from $x_{g}=5$. A gene embedding step clearly brings non-monotone expressivity in a language model. Anecdotally, "not" and "not, not, not" can be located in nearby locations apart from "not, not" if that's easier to picture. We do not specify their positions but learn semantic similarity from examples.</p>
<p>Okay, what about gene/word identity? Many single-cell foundation models include a positional embedding. If only the highly variable/expressed genes were considered, and subsequent gene-by-gene attention modules could have been mapped out in GPU memory, we wouldn't need to consider this. As long as we can feed genes in the same order, we are uniquely mapping gene symbols onto identity space. A token of the <em>g</em>-th position is always the same gene. Positional embedding would have been redundant. However, if the length of accessible genes from one cell to another greatly varies, and padding unexpressed genes/words with zeros is highly inefficient, we need to think of a cell as a series of tokens, just like a sentence of words dynamically rearranged. Here, a token $\neq$ a word.</p>
<h2 id="2-what-attention-mechanisms-can-do-with-gene-embedding-vectors"><a class="zola-anchor" href="#2-what-attention-mechanisms-can-do-with-gene-embedding-vectors" aria-label="Anchor link for: 2-what-attention-mechanisms-can-do-with-gene-embedding-vectors">2. What attention mechanisms can do with gene embedding vectors?</a></h2>
<p>Now, let's discuss the elephant in the room: What in the world is attention? <a href="https://papers.nips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html">Why is attention all you need?</a> First, we need to know what else has been considered so essential in previous work besides attention mechanisms. In NLP, a sentence of words has been modelled as a sequence of hidden states, such as recurrent neural network (RNN) models. One of the most recent RNN architectures is Long Short-Term Memory (LSTM), where the layer keeps the memory of previous words' hidden states to figure out the state of a current word. Since "memory" is not a part of the model parameters, it is somehow wasted, computationally cumbersome and not ideal for dealing with long sentences.</p>
<h3 id="how-can-we-represent-a-sentence-of-words-in-a-meaningful-way"><a class="zola-anchor" href="#how-can-we-represent-a-sentence-of-words-in-a-meaningful-way" aria-label="Anchor link for: how-can-we-represent-a-sentence-of-words-in-a-meaningful-way">How can we represent a sentence of words in a meaningful way?</a></h3>
<p>Okay. We need to model word-to-word dependency structures without inferring what each word's state could be. Why did we want to assign some latent states to words in a sentence? From the perspective of a hidden Markov model (a grandfather of a language model), knowing previous states, we can identify blocks of consecutive words, and then we can aggregate information within each block without too much loss of information. Keeping memory in the model is useful to parse out the meaning of a sentence. It might be an effective way to explain what the meaning of an overall sentence would be for a non-native English reader/writer, segmenting a sentence into multiple blocks (clauses), and so on. At the same time, such a pedagogy could become an obstacle when students want to generate a new sentence by themselves.</p>
<h3 id="an-attention-mechanism-simplifies-this-sentence-generating-process"><a class="zola-anchor" href="#an-attention-mechanism-simplifies-this-sentence-generating-process" aria-label="Anchor link for: an-attention-mechanism-simplifies-this-sentence-generating-process">An attention mechanism simplifies this sentence-generating process.</a></h3>
<p>It is like the way a baby learns a new language to me. A stream of words comes as a sentence. The first word will be understood together with other words that arrive later in the same sentence. It might be the imminent one or much later. As a neural model accumulates examples of sentences, associating the first word with others, the second with others, and so on, we can follow the probability of such word-to-word associations. Provided that the order of genes within a cell sentence/document is fixed, we can keep track of how frequently genes are jointly associated (or disassociated). For each gene, we can fit a softmax function (probability) to learn about frequent "neighbours" in the embedded space. Well, very roughly. For this type of process, there is no memory of word-specific states. In other words, if we consider a single cell as a scene of a movie or play, we don't need to know whether a gene plays an antagonist or protagonist in the scene. We just need to know who else appears here and how they interact with one another.</p>
<h3 id="hashing-dictionary-and-query-key-and-value"><a class="zola-anchor" href="#hashing-dictionary-and-query-key-and-value" aria-label="Anchor link for: hashing-dictionary-and-query-key-and-value">Hashing, dictionary, and (query, key, and value)</a></h3>
<p>Interactions between genes matter, and keeping track of interactions is our only interest. For simplicity, although we don't need to do so, let's assume that gene embedding coordinates are fixed.</p>
<p><img src="https://ypark.github.io/posts/transformer-attention-network/self_attention.png" alt="" /></p>
<p>We need to bring two genes closer if they talk to each other more frequently than others. Borrowing the concept of <a href="https://dl.acm.org/doi/abs/10.1145/276698.276876">locality sensitive hashing</a>, we use a <em>query</em> of one gene to locate neighbouring genes according to their <em>key</em> in the embedding space. For closer gene pairs <em>key</em> and <em>query</em> should be similar, while distant pairs have largely independent <em>key</em> and <em>query</em> patterns. We could revise the embedding coordinates directly based on semantic similarity scores. However, if we want to stack up this gene-to-gene matching process within many different contexts, defining additional transformation functions for key and query vectors can render a more general modelling capability. More specifically, for the embedding vector of a gene $g_{1}$, namely $x_{g_{1}}$, and other $g_{2}$, namely $x_{g_{2}}$, we transform them into $[Q_{g_{1}1}, \ldots, Q_{g_{1}d}]$ and $[K_{g_{2}1},\ldots,K_{g_{2}d}]$, $d$-vectors. Then, we test how well the query and key vectors agree with each other by taking the dot product; this proximity information can be scaled and converted to a probably by the softmax transformation.</p>
<p>$$\textsf{Attention}(Q,K,V) = \underbrace{ \textsf{softmax}\left( \frac{QK^{\top}}{\sqrt{d}} \right) }_{\color{blue}\textsf{proximity between genes}} V.$$</p>
<p>The value vectors, $V$, map how each gene can work. Roughly, we may think of a traditional fully connected neural network layer as a diagonal attention matrix and only the V matrix. There, we encode gene expression patterns into some hidden codes. Putting them all together, in terms of the scene analogy, genes act on some value $V$ here, while interacting with their partners and influencing one another. In the next scene, we see the consolidated net effects of the entire scene.  Sure, we may rule out some genes/actors in the current scene as they fit in the story. Moreover, instead of considering all pairwise interactions, we may restrict/focus on feasible interactions, potentially set by physical constraints, such as protein-protein interactions and cellular locations.</p>
<h2 id="3-can-attention-based-models-be-foundational-for-single-cell-rna-seq-modelling"><a class="zola-anchor" href="#3-can-attention-based-models-be-foundational-for-single-cell-rna-seq-modelling" aria-label="Anchor link for: 3-can-attention-based-models-be-foundational-for-single-cell-rna-seq-modelling">3. Can attention-based models be foundational for single-cell RNA-seq modelling?</a></h2>
<p>I think gene embedding is a good idea. Well, I also like the way we represent gene-gene interactions as a stack of attention layers. But could we derive a foundational model? For a model to be foundational, well, what features, characteristics, or properties should a model possess and demonstrate? Very roughly... If we roughly consider each transformer layer modelled by attention networks as a scene or a set of rules for generating a scene, we may be able to run a realistic show with fifty of them stacked together, so is true with diffusion-based models. Well, is it foundational? We may need to define what the "foundation" model exactly means, though. I will leave all these sorts of questions for other posts.</p>

        </section>
    </article>
</main>



        

    </div>
</body>

</html>
